# 🧠 Doctor AI — Multi-Modal Medical Assistant

An intelligent **multi-modal AI system** that mimics how a real doctor communicates. Users can **speak** their symptoms and **upload an image**, and the bot will analyze the input using advanced **LLMs**, **vision models**, and **TTS synthesis** to deliver a **human-like medical voice response**.

## 🚀 Features

- 🎤 **Voice Input**: Speak symptoms directly to the system
- 🖼️ **Image Upload**: Upload medical images (e.g., rashes, X-rays)
- 🧠 **LLM + Vision Analysis**: Uses GROQ's LLaMA-3 Vision model for intelligent reasoning
- 🔊 **Text-to-Speech Response**: Responds with a lifelike medical voice using TTS
- 🔄 **Multi-modal Fusion**: Combines voice and visual context for a better diagnosis

---

## 🛠️ Tech Stack

## 🧠 Tech Stack

| Feature            | Technology Used             |
|--------------------|-----------------------------|
| 🎤 Audio Input     | Gradio                      |
| 🗣️ Speech-to-Text (STT) | OpenAI Whisper via Groq     |
| 👁️ Vision + LLM     | Meta LLaMA + Groq            |
| 🗣️ Text-to-Speech (TTS) | ElevenLabs                  |
| 🖼️ UI Framework     | Gradio                      |

---

## Screenshots of responses(Text+Audio) :
![image](https://github.com/user-attachments/assets/6ef3b156-24f1-46a5-b098-5184deb7ca86)

![image](https://github.com/user-attachments/assets/eabb3021-73d6-4255-bf56-d1f35de3d69a)

![image](https://github.com/user-attachments/assets/f22020c0-77dd-42eb-87e5-b3f5cf530c5b)



